  %! TeX program = lualatex
\documentclass[12pt]{amsart}

\input{usepackages}
\input{theoremenv}
\input{title}
\input{mathdefs}

\addbibresource{ref.bib}

\begin{document}
\maketitle

\section{Background}
Many real-world routing and scheduling problems are subject to uncertainty. Take delivery service as an example, a courier has several customers located at different cities and it needs to plan a route that visits the customers. The delivery person may find that 
a household might not have packages to deliver today, or customer requests can be canceled, etc..
A classical abstraction is the stochastic
traveling salesperson problem (stochastic TSP), where each vertex $v_v$ comes with a specified probability $p_v$ and becomes \textit{active} (requires service) independently with probabilty $p_i$. The goal is to visit all active vertices and minimize the expected travel cost.

An important modeling choice is whether the model could make adapted decision based on information revealed during execution or additional information known beforehand. In the non-adaptive (a priori) setting, one commits to a master tour and, after the set of active vertices is realized, follows the tour while shortcutting inactive vertices. In the adaptive setting, decisions may depend on observations revealed along the way, allowing the route to be adjusted on the fly. A fundamental question is how much adaptivity can improve performance.
Understanding the quantitative advantage of adaptivity and designing provably good adaptive strategies helps us making better policies.

Thus we want to study the relationship between adaptive and non-adaptive stochastic policies,
aiming to bound (upper/lower bound) the performance gap and to develop policies with provable performance guarantees.

It's worth noting that optimal solution for stochastic TSP problem is computationally hard, following from the fact that it is a generalization of classical TSP, which is proved to be NP-Complete\cite{Karp1972}. However, approximation algorithms with constant approximation ratio in polynomial time are known for both symmetric metrics\cite{Christofides1973}\cite{Karlin2021} and asymmetric metrics\cite{Svensson2020}.

\section{Notations and Definitions}
Let $(V,d)$ be a finite metric space with distance function $d$ satisfying the triangle inequality. A metric is called symmetric if $d(x, y) = d(y, x)$ for any $x, y$.

For classical TSP, we are given the finite metric space $(V, d)$ as input and we want to find a tour $\tau$, which is a cyclic permutation of $V$, such that total length of the tour $c(\tau) := \sum_{i \in V} c(i, \tau(i))$ is minimized. 

In stochastic setting, the set of active vertices is a subset $A \subseteq V$ generated by independent activations: each vertex $v \in V$ is active (i.e., $v \in A$) independently with probability $p_v$.
It precisely models a delivery planning the delivery route for customers located at different places and each customer needs delivery with a specified probability independently.

A key distinction between common formulations of stochastic TSP is \textit{when} the algorithm learns which vertices are active and how much it is allowed to change its route \textit{adaptively} in response. We study three variants, \textit{a posteriori}, \textit{a priori} and \textit{adaptive} TSP, which corresponds to three levels of information and adaptivity.

\subsection{a posterior TSP}
The delivery person knows in advance exactly which customers will need service today (e.g., everyone has already confirmed beforehand). Then we can plan the optimal tour for todayâ€™s realized requests.
a posterior TSP\cite{Shmoys2008} each time asks one to give a tour after we know which vertices would be activated.
In this case we are basically solving classical TSP each time and we can make the most adaptive decision since we know exactly which vertices would be activated. Let $\opt_A$ denotes the minimum cost of a tour in a deterministic TSP instance induced by $A$ and our object is to minimize 
$$
\E_{A \sim \mu} [\opt_A]
$$

where $\mu$ is the distribution of active vertices subsets defined by $\mu(A) = \Pi_{v \in A}p_v \cdot \Pi_{v \notin A}(1 - p_v)$.

\subsection{a priori (non-adaptive) TSP}
The delivery person in  this case doesn't know which customers A priori TSP asks one to choose a master tour $T$ visiting all vertices in certain order.
After active subsets $A$ is known, one cannot make any adjustments but the executed tour is
solely obtained by shortcutting $T$ to visit only vertices in $A$. The objective is 
$$
\min_{T} \E_{A} [\text{cost}(T|_{A})]
$$ 

where $T|_{A}$ stands for tour $T$ shortcutted on $A$ and $A$ is the activated subset of vertices.

In this case we can make no adaptive decision since the tour is determined before
we know anything about $A$.

\subsection{Adaptive TSP}
Adaptive TSP asks one to choose a vertex to probe in each round. Once probing is done, we 
can know if the probed vertex is activated or not. If it is activated, we have to 
visit this vertex as next move; if it is not activated, we do nothing and get into next round.
The object is 
$$
\min_{T} \E_{A} [\text{cost}(T_{\sim A})]
$$

where $T_{\sim A}$ indicated the tour generated by our adaptive policy (a decision tree) with the input:
activated vertices $A$.

\section{Research Question}
A priori TSP is the most non-adaptive policy, since we can't adjust our strategy at all.
A posteriori TSP is the most adaptive policy where we can always know which vertices would 
be activated and then make our decision.
The ratio between optimal value of A priori and A posteriori is called adaptivity gap.
Clearly adaptive TSP lies in between, so our question would be, where does the adaptive TSP exactly lie between?

Concretely:

\begin{enumerate}
    \item \textbf{Gap characterization}: Prove upper and lower bounds on $\frac{\opt_{prior}}{\opt_{adapt}}$ and 
        construct instances demonstrating tightness. This mostly is a mathematical question, where we don't pay much attention to the efficiency or space usage of the algorithm. It's worth noting that this gap in symmetric case would be $O(1)$, precisely we already know upper bound $$ 
    \item \textbf{Algorithm design}: Develop adaptive strategies with approximation guarantees.
    \item \textbf{Discovering other metrics}: Obtain stronger results on other metrics like tree metrics then 
        extend the result by tree embedding.
\end{enumerate}


\printbibliography

\end{document}
