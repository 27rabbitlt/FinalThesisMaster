  %! TeX program = lualatex
\documentclass[12pt]{amsart}

\input{usepackages}
\input{theoremenv}
\input{title}
\input{mathdefs}

\addbibresource{ref.bib}

\begin{document}
\maketitle

\section{Background}
Many real-world routing and scheduling problems are subject to uncertainty: 
this house might not have mails to deliver, customer requests can be canceled.
Tasks may appear only with some probability. A classical abstraction is the stochastic
traveling salesman problem (stochastic TSP), where each vertex may become 
“active” (requires service) according to a known probability distribution, 
and the goal is to minimize the expected travel cost.

An interesting question is how much adaptivity helps. In the non-adaptive (a priori) setting,
one has to stick to a master tour in advance and later shortcuts it according to 
which vertices turn out active. In the adaptive setting, decisions can depend on
observations revealed during execution. Understanding the quantitative advantage
of adaptivity and designing provably good adaptive strategies helps us making better policies.

We want to studie the relationship between adaptive and non-adaptive stochastic policies,
aiming to bound (upper/lower bound) the performance gap and to develop strategies with provable guarantees.

\section{Notations and Definitions}
Let $(V, d)$ be a finite metric space (symmetric distances satisfying triangle inequality).
A random subset $A \subset V$ of active vertices is drawn from a known distribution.
Here we always consider the independent activation modle where each vertex $v$ is active
independently with probability $p_v$.

\subsection{A priori (non-adaptive) TSP}
A priori TSP asks one to choose a master tour $T$ visiting all vertices in certain order.
After active subsets $A$ is known, one cannot make any adjustments but the executed tour is
solely obtained by shortcutting $T$ to visit only vertices in $A$. The objective is 
$$
\min_{T} \E_{A} [\text{cost}(T|_{A})]
$$ 

where $T|_{A}$ stands for tour $T$ shortcutted on $A$ and $A$ is the activated subset of vertices.

In this case we can make no adaptive decision since the tour is determined before
we know anything about $A$.

\subsection{A posterior TSP}
A posterior TSP\cite{Shmoys2008} each time asks one to give a tour after we know which vertices would be activated.
In this case we are basically solving classical TSP each time and we can make 
the most adaptive decision since we know exactly which vertices would be activated.
The object is
$$
\min_{T} \E_{A} [\text{cost}(T_{A})]
$$

where $T_{A}$ denotes the optimal TSP tour for subset $A$.

\subsection{Adaptive TSP}
Adaptive TSP asks one to choose a vertex to probe in each round. Once probing is done, we 
can know if the probed vertex is activated or not. If it is activated, we have to 
visit this vertex as next move; if it is not activated, we do nothing and get into next round.
The object is 
$$
\min_{T} \E_{A} [\text{cost}(T_{\sim A})]
$$

where $T_{\sim A}$ indicated the tour generated by our adaptive policy (a decision tree) with the input:
activated vertices $A$.

\section{Research Question}
A priori TSP is the most non-adaptive policy, since we can't adjust our strategy at all.
A posteriori TSP is the most adaptive policy where we can always know which vertices would 
be activated and then make our decision.
The ratio between optimal value of A priori and A posteriori is called adaptivity gap.
Clearly adaptive TSP lies in between, so our question would be, where does the adaptive TSP exactly lie between?

Concretely:

\begin{enumerate}
    \item \textbf{Gap characterization}: Prove bounds on $\frac{\text{OPT}_{a \; priori}}{\text{OPT}_{adaptive}}$ and 
        construct instances demonstrating tightness.
    \item \textbf{Algorithm design}: Develop adaptive strategies with approximation guarantees.
    \item \textbf{Discovering other metrics}: Obtain stronger results on other metrics like tree metrics then 
        extend the result by tree embedding.
\end{enumerate}


\printbibliography

\end{document}
