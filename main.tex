  %! TeX program = lualatex
\documentclass[12pt]{amsart}

\input{usepackages}
\input{theoremenv}
\input{title}
\input{mathdefs}

\addbibresource{ref.bib}

\begin{document}
\maketitle

\section{Background}
Many real-world routing and scheduling problems are subject to uncertainty. Take delivery service as an example, a courier has several customers located at different cities and it needs to plan a route that visits the customers. The delivery person may find that 
a household might not have packages to deliver today, or customer requests can be canceled, etc..
A classical abstraction is the stochastic
traveling salesperson problem (stochastic TSP), where each vertex $v_v$ comes with a specified probability $p_v$ and becomes \textit{active} (requires service) independently with probabilty $p_i$. The goal is to visit all active vertices and minimize the expected travel cost.

An important modeling choice is whether the model could make adapted decision based on information revealed during execution or additional information known beforehand. In the non-adaptive (a priori) setting, one commits to a master tour and, after the set of active vertices is realized, follows the tour while shortcutting inactive vertices. In the adaptive setting, decisions may depend on observations revealed along the way, allowing the route to be adjusted on the fly. A fundamental question is how much adaptivity can improve performance.
Understanding the quantitative advantage of adaptivity and designing provably good adaptive strategies helps us making better policies.

Thus we want to study the relationship between adaptive and non-adaptive stochastic policies,
aiming to bound (upper/lower bound) the performance gap and to develop policies with provable performance guarantees.

It's worth noting that optimal solution for stochastic TSP problem is computationally hard, following from the fact that it is a generalization of classical TSP, which is proved to be NP-Complete\cite{Karp1972}. However, approximation algorithms with constant approximation ratio in polynomial time are known for both symmetric metrics\cite{Christofides1973}\cite{Karlin2021} and asymmetric metrics\cite{Svensson2020}.

\section{Notations and Definitions}
Let $(V,d)$ be a finite metric space with distance function $d$ satisfying the triangle inequality. A metric is called symmetric if $d(x, y) = d(y, x)$ for any $x, y$.

For classical TSP, we are given the finite metric space $(V, d)$ as input and we want to find a tour $\tau$, which is a cyclic permutation of $V$, such that total length of the tour $c(\tau) := \sum_{i \in V} c(i, \tau(i))$ is minimized. 

In stochastic setting, the set of active vertices is a subset $A \subseteq V$ generated by independent activations: each vertex $v \in V$ is active (i.e., $v \in A$) independently with probability $p_v$.
It precisely models a delivery planning the delivery route for customers located at different places and each customer needs delivery with a specified probability independently.

A key distinction between common formulations of stochastic TSP is \textit{when} the algorithm learns which vertices are active and how much it is allowed to change its route \textit{adaptively} in response. We study three variants, \textit{a posteriori}, \textit{a priori} and \textit{adaptive} TSP, which corresponds to three levels of information and adaptivity.

\subsection{a posterior TSP\texorpdfstring{\cite{Shmoys2008}}{}}
The delivery person knows in advance exactly which customers will need service today (e.g. everyone has already confirmed beforehand). Then we can plan the optimal tour for todayâ€™s realized requests.
a posterior TSP each time asks one to give a tour after we know which vertices would be activated.
In this case we are basically solving classical TSP each time and we can make the most adaptive decision since we know exactly which vertices would be activated. Let $\opt_A$ denotes the minimum cost of a tour in a deterministic TSP instance induced by $A$ and our object is to minimize 
$$
\E_{A \sim \mu} [\opt_A]
$$

where $\mu$ is the distribution of active vertices subsets defined by $\mu(A) = \Pi_{v \in A}p_v \cdot \Pi_{v \notin A}(1 - p_v)$.

\subsection{a priori (non-adaptive) TSP\texorpdfstring{\cite{Jaillet1985}}{}}
The delivery person in this case doesn't know which customers will be activated. The person will decide a master tour $T$ in advance given only the probability information $\{p_v\}$, and commit to this tour even after activated customers information are gradually revealed along the tour. The executed tour is solely obtained by shortcutting $T$ to include only vertices in $A$. For a certain master tour $T$,
the cost is defined as the $c(T_A)$ being the length of $T$ after shortcutting to include only $A$. Eventually, we want to minimize 
$$
\E_{A\sim \mu} [c(T_A)]
$$ 

In this case we can make no adaptive decision since the tour is determined before we know anything about $A$.

\subsection{adaptive TSP}
The delivery person also doesn't know which customers will be activated. The person each time will decide a customer to call according to a policy based on current information revealed (i.e. current position and which vertices are known to be activated). If a customer responds that he/she needs service then the delivery person has to go to the customer's city and provide service; otherwise the delivery person doesn't need to do anything.

Precisely, adaptive TSP asks for a policy to choose a vertex to call in each round based on current information. After calling we know if the called vertex is activated or not. If it is activated, we have to visit this vertex as next move; if it is not activated, we do nothing and get into next round. 

Formally, an adaptive policy is a (deterministic) function $\pi: V \times 2^V \times \{0, 1\}^S \rightarrow V \setminus S$,
which, given the current location $l_t \in V$, queried set $S_t \subset V$, and observed activation outcome $X_{S_t} \in \{0, 1\}^{S_t}$,
selects the next vertex $q_t = \pi(l_t, S_t, X_{S_t})$ to call. After querying $q_t$, the algorithm observes $x_{q_t}$ and updates $S_{t+1} = S_t \cup \{q_t\}$. Here the ovserved activation outcome $X_{S_t}$ is defined as $S_t \cap A$, which is the active vertices currently revealed.
The movement is then forced by the rule:

$$
l_{t+1} = 
\begin{cases}
    q_t, \;\; &\text{if} \;\; x_{q_t} = 1 \\
    l_t, \;\; &\text{if} \;\; x_{q_t} = 0
\end{cases}
$$

and the incurred travel cost at step $t$ is $d(l_t, l_{t+1})$.

A policy is feasible if for every realization $A \subseteq V$ it eventually queries every vertex
and hence visits every active vertex.

The objective is to find a feasible policy minimizing

$$
\E_{A\sim \mu} [c(\pi_{A})]
$$

where $\pi_A$ is the tour generated by policy $\pi$ together with the realization of active vertex subset $A$.
The cost of the generated tour is simply the sum of distance at each step, which we defined above.

\section{Research Question}
A priori TSP is the most non-adaptive policy, since we can't adjust our strategy at all.
A posteriori TSP is the most adaptive policy where we can always know which vertices would 
be activated and then make our decision.
The ratio between optimal value of A priori and A posteriori is called adaptivity gap.
Clearly adaptive TSP lies in between, so our question would be, where does the adaptive TSP exactly lie between?
Define $\opt_{post}$ to be the optimal cost under a posteriori TSP setting given the instance, and define $\opt_{prior}$ and $\opt_{adapt}$ 
respectively for a priori and adaptive setting. Then our research question can be described as:

\begin{enumerate}
    \item \textbf{Gap characterization}: Prove upper and lower bounds on $\frac{\opt_{prior}}{\opt_{adapt}}$ and 
        construct instances demonstrating tightness. This mostly is a mathematical question, 
        where we don't pay much attention to the efficiency or space usage of the algorithm.
        It's worth noting that this gap in symmetric case would be $O(1)$, 
        precisely we already have $3$ as the upper bound\cite{Shmoys2008};
        in asymmetric case, we have upper bound $O(\sqrt{n})$ and lower bound $\Omega(n^{1/4} / \log n)$\cite{Christalla2025} 
        with $n$ being the $n = |V|$. It's also important to consider the gap $\frac{\opt_{adapt}}{\opt_{post}}$, 
        since it gives us the insight about whether it's already good enough to consider only limited information
        about active vertices.
    \item \textbf{Algorithm design}: Develop compact adaptive policies with provable approximation guarantees.
    % \item \textbf{Discovering other metrics}: Obtain stronger results on other metrics like tree metrics then 
    %     extend the result by tree embedding.
\end{enumerate}


\printbibliography

\end{document}
